{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from os.path import join\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def print_args(path):\n",
    "    with open(path) as args:\n",
    "        print(args.read())\n",
    "        \n",
    "def read_run_results(run_name, verbose=False):\n",
    "    print('Reading results for {}'.format(run_name))\n",
    "    print(' ')\n",
    "    \n",
    "    if verbose:\n",
    "        print('AGENT ARGS')\n",
    "        agent_args = join('/Users/adam/git/energy_py/energy_py/experiments/results/', run_name, 'agent_args.txt')\n",
    "        print_args(agent_args)\n",
    "        print('ENV ARGS')\n",
    "        env_args = os.path.join('/Users/adam/git/energy_py/energy_py/experiments/results/', run_name, 'env_args.txt')\n",
    "        print_args(env_args)\n",
    "\n",
    "    results = []\n",
    "    results_path = join('/Users/adam/git/energy_py/energy_py/experiments/results/', run_name, 'env_histories')\n",
    "    for root, dirs, files in os.walk(results_path):\n",
    "        for f in files:\n",
    "            results.append(pd.read_csv(join(root, f), index_col=0, parse_dates=True))\n",
    "\n",
    "    print('Read {} results'.format(len(results)))\n",
    "    print(' ')\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_result(result, verbose=False):\n",
    "    useful_cols = ['reward', 'flex_counter', 'flex_action', 'flex_up', 'flex_down', 'electricity_price']\n",
    "    result = result[useful_cols]\n",
    "\n",
    "    total_reward = result['reward'].sum()\n",
    "    num_actions = result['flex_counter'].max()\n",
    "\n",
    "    output = {'number flex actions': num_actions,\n",
    "              'total episode reward [$]': total_reward}\n",
    "\n",
    "    if verbose:\n",
    "        groups = {}\n",
    "        groups['electricity_price'] = [np.mean, np.max, np.min]\n",
    "        groups['flex_up'] = [np.sum]\n",
    "        groups['flex_down'] = [np.sum]\n",
    "        groups['flex_up'] = [np.sum]\n",
    "        \n",
    "        group = result.groupby('flex_counter').agg(groups)\n",
    "        print(group)\n",
    "\n",
    "        for k, v in output.items():\n",
    "            print('{} {:2.0f}'.format(k, v))\n",
    "\n",
    "    return output\n",
    "\n",
    "def plot_result(hist):\n",
    "    hist = hist.iloc[-200:, :]\n",
    "    f, ax = plt.subplots(nrows=3, figsize=(20, 10))\n",
    "\n",
    "    hist.plot(y='flex_action', x=hist.index, color='g', ax=ax[0])\n",
    "    #_ = ax[0].set_title('flex_action [MW]')\n",
    "\n",
    "    hist.plot(y='reward', x=hist.index, color='r', ax=ax[1])\n",
    "    #_ = ax[1].set_title('reward [$/5min]')\n",
    "\n",
    "    hist.plot(y='electricity_price', x=hist.index, color='b', ax=ax[2])\n",
    "    #_ = ax[2].set_title('electricity_price [$/MWh]')\n",
    "    return f\n",
    "        \n",
    "\n",
    "class Results(object):\n",
    "    \"\"\"\n",
    "    Processes environment histories\n",
    "    \n",
    "    args\n",
    "        run_name (path) /expt_name/run_name\n",
    "        verbose (bool)\n",
    "    \"\"\"\n",
    "    def __init__(self, run_name, verbose=False):\n",
    "        self.run_name = run_name\n",
    "        \n",
    "        self.results = read_run_results(self.run_name, verbose)\n",
    "        \n",
    "        #assert self.results[0].shape[0] == self.results[0].shape[-1]\n",
    "        self.episode_length = self.results[-1].shape[0]\n",
    "        \n",
    "        self.episode_summary = self.summarize_results()\n",
    "        \n",
    "    def summarize_results(self):\n",
    "        result_summary = defaultdict(list)\n",
    "\n",
    "        for result in self.results:\n",
    "            out = process_result(result)\n",
    "            for k, v in out.items():\n",
    "                result_summary[k].append(v)\n",
    "                \n",
    "        episode_summary = pd.DataFrame().from_dict(result_summary)\n",
    "        \n",
    "        num_5mins_per_day = 12 * 24\n",
    "        num_5mins_per_year = num_5mins_per_day * 365\n",
    "        \n",
    "        avg_ep_reward = episode_summary['total episode reward [$]'].mean()\n",
    "        avg_daily_reward = avg_ep_reward / (self.episode_length / num_5mins_per_day)\n",
    "        avg_annual_reward = avg_ep_reward / (self.episode_length / num_5mins_per_year)\n",
    "\n",
    "        print('Results for {}'.format(self.run_name))\n",
    "        print(' ')\n",
    "        print('avg episode reward [$] {:2.0f}'.format(avg_ep_reward))\n",
    "        print('avg daily reward [$] {:2.0f}'.format(avg_daily_reward))\n",
    "        print('avg annual reward [$] {:2.0f}'.format(avg_annual_reward))\n",
    "\n",
    "        num_eps_no_flex = episode_summary[episode_summary['number flex actions'] == 0].shape[0]\n",
    "        print('num episodes without flexing {} of {} days'.format(num_eps_no_flex, episode_summary.shape[0]))\n",
    "        \n",
    "        num_eps_losses = episode_summary[episode_summary['total episode reward [$]'] < 0].shape[0]\n",
    "        print('num episodes of losses {}'.format(num_eps_losses))\n",
    "        \n",
    "        all_results = pd.concat(self.results, axis=0)\n",
    "        monthly = all_results['reward'].groupby(all_results.index.month).sum()\n",
    "        print(monthly)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading results for naive_flex/auto\n",
      " \n",
      "AGENT ARGS\n",
      "total_steps,315360\n",
      "env,<energy_py flex-v0 environment>\n",
      "env_repr,<energy_py flex-v0 environment>\n",
      "sess,<tensorflow.python.client.session.Session object at 0x12036bda0>\n",
      "learn_path,/Users/adam/git/energy_py/energy_py/experiments/results/naive_flex/tensorboard/auto/learn\n",
      "act_path,/Users/adam/git/energy_py/energy_py/experiments/results/naive_flex/tensorboard/auto/act\n",
      "agent_id,auto_flex\n",
      "seed,42\n",
      "\n",
      "ENV ARGS\n",
      "flex_time,6\n",
      "episode_length,315360\n",
      "episode_sample,fixed\n",
      "env_id,flex-v0\n",
      "relax_time,0\n",
      "flex_size,1\n",
      "flex_effy,1.00\n",
      "dataset,tempus\n",
      "\n",
      "Read 1 results\n",
      " \n",
      "Results for naive_flex/auto\n",
      " \n",
      "avg episode reward [$] 260210\n",
      "avg daily reward [$] 238\n",
      "avg annual reward [$] 86737\n",
      "num episodes without flexing 0 of 1 days\n",
      "num episodes of losses 0\n",
      "SETTLEMENTDATE\n",
      "1     14392.537500\n",
      "2     33424.872500\n",
      "3     15946.120833\n",
      "4     11351.481667\n",
      "5     19372.015000\n",
      "6     23681.194167\n",
      "7     54235.083333\n",
      "8     18422.688333\n",
      "9     10883.445000\n",
      "10    11341.879167\n",
      "11    18994.764167\n",
      "12    28164.118333\n",
      "Name: reward, dtype: float64\n",
      "Reading results for naive_flex/time\n",
      " \n",
      "AGENT ARGS\n",
      "total_steps,315360\n",
      "act_path,/Users/adam/git/energy_py/energy_py/experiments/results/naive_flex/tensorboard/time/act\n",
      "env_repr,<energy_py flex-v0 environment>\n",
      "seed,42\n",
      "hours,\"6,9,17,20\"\n",
      "learn_path,/Users/adam/git/energy_py/energy_py/experiments/results/naive_flex/tensorboard/time/learn\n",
      "agent_id,time_flex\n",
      "env,<energy_py flex-v0 environment>\n",
      "sess,<tensorflow.python.client.session.Session object at 0x120b71be0>\n",
      "\n",
      "ENV ARGS\n",
      "episode_length,315360\n",
      "env_id,flex-v0\n",
      "flex_effy,1.00\n",
      "relax_time,0\n",
      "episode_sample,fixed\n",
      "flex_time,36\n",
      "dataset,tempus\n",
      "flex_size,1\n",
      "\n",
      "Read 1 results\n",
      " \n",
      "Results for naive_flex/time\n",
      " \n",
      "avg episode reward [$] 144231\n",
      "avg daily reward [$] 132\n",
      "avg annual reward [$] 48077\n",
      "num episodes without flexing 0 of 1 days\n",
      "num episodes of losses 0\n",
      "SETTLEMENTDATE\n",
      "1      2931.975\n",
      "2     41956.225\n",
      "3      6363.855\n",
      "4      7385.570\n",
      "5     14548.195\n",
      "6     11582.135\n",
      "7     31946.490\n",
      "8     11357.630\n",
      "9      5958.585\n",
      "10     8931.390\n",
      "11     3762.940\n",
      "12    -2494.010\n",
      "Name: reward, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "runs = ['naive_flex/auto', 'naive_flex/time']\n",
    "runs = {run_name: Results(run_name, verbose=True) for run_name in runs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting single episode of naive_flex/time\n",
      " \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d6549099a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_single_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'naive_flex/time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4d6549099a98>\u001b[0m in \u001b[0;36mplot_single_episode\u001b[0;34m(run)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def plot_single_episode(run):\n",
    "    print('plotting single episode of {}'.format(run.run_name))\n",
    "    print(' ')\n",
    "    results = run.results\n",
    "\n",
    "    selected = random.randint(0, len(results))\n",
    "    selected = results[selected]\n",
    "\n",
    "    _ = process_result(selected, verbose=True)\n",
    "\n",
    "    _ = plot_result(selected)\n",
    "    \n",
    "plot_single_episode(runs['naive_flex/time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_episode(runs['naive_flex/auto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
