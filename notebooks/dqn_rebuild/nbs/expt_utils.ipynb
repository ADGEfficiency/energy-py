{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff like Runners, Statistics, logging to tensorboard, saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/envs/energy_py/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from energy_py import ensure_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saver and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saver(object):\n",
    "    \"\"\"\n",
    "    Inspired by deep-rl-tensorflow Statistic object\n",
    "    \n",
    "    Would want to give this model a list of the variables for acting (ie the online net), \n",
    "    or could do more ifwanted to learn later\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sess, model_dir, variables):\n",
    "        self.sess = sess\n",
    "        self.model_dir = model_dir\n",
    "                                                                              \n",
    "        ensure_dir(self.model_dir)\n",
    "                \n",
    "        self.step = tf.Variable(1, name='saver_step', dtype=tf.int32)\n",
    "        self.increase_step = self.step.assign_add(1)\n",
    "        \n",
    "        variables = variables + [self.step]\n",
    "        self.saver = tf.train.Saver(variables, max_to_keep=20)\n",
    "        print(variables)\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Saves the variables\n",
    "        \n",
    "        tf.train.global_step = the number of batches seen by the graph - not what we want\n",
    "        \"\"\"\n",
    "        print('Saving model checkpoint')\n",
    "        self.saver.save(self.sess, self.model_dir, global_step=self.step)\n",
    "        self.sess.run(self.increase_step)\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads variables from a model checkpoint in model_dir\n",
    "        \"\"\"\n",
    "        checkpoint = tf.train.get_checkpoint_state(self.model_dir)\n",
    "        \n",
    "        if checkpoint and checkpoint.model_checkpoint_path:\n",
    "            checkpoint_name = os.path.basename(checkpoint.model_checkpoint_path)\n",
    "            \n",
    "            filename = os.path.join(self.model_dir, checkpoint_name)\n",
    "            \n",
    "            self.saver.restore(self.sess, filename)\n",
    "            print('Loaded model checkpoint {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'saver_step:0' shape=() dtype=int32_ref>]\n",
      "save_step 1 out 0.0\n",
      "Saving model checkpoint\n",
      "save_step 2 out 1.0\n",
      "Saving model checkpoint\n",
      "save_step 3 out 4.0\n",
      "Saving model checkpoint\n"
     ]
    }
   ],
   "source": [
    "def make_graph(scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "        y = tf.placeholder(shape=(None), dtype=tf.float32)\n",
    "        out = tf.multiply(x, y)\n",
    "    \n",
    "    return x, y, out\n",
    "\n",
    "x, y, out = make_graph('saver')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='saver')\n",
    "    s = Saver(sess, './model_dir/', variables)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(3):\n",
    "        save_step, o = sess.run([s.step, out], {x: step, y: step})\n",
    "        print('save_step {} out {}'.format(save_step, o))\n",
    "        \n",
    "        s.save_model()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'saver_step:0' shape=() dtype=int32_ref>]\n",
      "INFO:tensorflow:Restoring parameters from ./model_dir/-3\n",
      "Loaded model checkpoint ./model_dir/-3\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x, y, out = make_graph('saver')\n",
    "\n",
    "with tf.Session() as new_sess:\n",
    "    \n",
    "    variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='saver')\n",
    "    new_s = Saver(new_sess, './model_dir/', variables)\n",
    "    \n",
    "    new_s.load_model()\n",
    "    \n",
    "    loaded_step = new_sess.run(new_s.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energy_py import ensure_dir\n",
    "\n",
    "\n",
    "class ExperimentStatsMan(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 sess, \n",
    "                 tb_dir):\n",
    "        \n",
    "        self.sess = \n",
    "        \n",
    "        ensure_dir(tb_dir)\n",
    "        self.writer = tf.summary.FileWriter(tb_dir, self.sess.graph)\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.episode_rewards = []\n",
    "        self.current_episode_rewards = [] \n",
    "        \n",
    "    def record_step(self, step, reward):\n",
    "        print('Recording step {}'.format(step))\n",
    "        \n",
    "        self.current_episode_rewards.append(reward)\n",
    "        \n",
    "    def record_episode(self):\n",
    "        \n",
    "        total_episode_reward = sum(self.current_episode_rewards)\n",
    "        self.episode_rewards.append(total_episode_reward)\n",
    "        \n",
    "        print('Recorded episode {}'.format(len(self.episode_rewards)))\n",
    "        \n",
    "        summaries = {\n",
    "            'total_episode_reward': total_episode_reward,\n",
    "            'avg_rew': np.mean(self.episode_rewards[-50:]),\n",
    "            'min_rew': np.min(self.episode_rewards[-50:]),\n",
    "            'max_rew': np.max(self.episode_rewards[-50:])\n",
    "        }\n",
    "        \n",
    "        for tag, value in summmaries:\n",
    "            summ = tf.Summary(\n",
    "                value=[tf.Summary.Value(tag=tag, value=float(value))]\n",
    "            )\n",
    "            self.writer.add_summary(summary, len(self.episode_rewards))\n",
    "        S\n",
    "        self.current_episode_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording step 0\n",
      "Recording step 1\n",
      "Recording step 2\n",
      "Recorded episode 1\n",
      "Recording step 0\n",
      "Recording step 1\n",
      "Recording step 2\n",
      "Recording step 3\n",
      "Recording step 4\n",
      "Recording step 5\n",
      "Recording step 6\n",
      "Recording step 7\n",
      "Recording step 8\n",
      "Recorded episode 2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    e = ExperimentStatsMan(sess, './tb_dir')\n",
    "    \n",
    "    for step in range(3):\n",
    "        e.record_step(step, step * 3)\n",
    "    e.record_episode()\n",
    "    \n",
    "    for step in range(9):\n",
    "        e.record_step(step, step * 3)\n",
    "    e.record_episode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizer\n",
    "\n",
    "Wraps around tensorboard stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarizer(object):\n",
    "    \n",
    "    def __init__(self, sess, summaries, log_dir=None):\n",
    "        summaries = summaries\n",
    "        self.summary_op = tf.summary.merge(inputs=summaries)\n",
    "        \n",
    "        self.summarizer = tf.summary.FileWriter(\n",
    "            logdir=None,\n",
    "            graph=self.sess.graph,\n",
    "            )\n",
    "    \n",
    "    def write_summaries(self, summaries):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
