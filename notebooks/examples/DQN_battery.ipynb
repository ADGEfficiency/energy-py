{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning with Battery Example\n",
    "This notebook demonstrates the ability of a DQN agent to learn to optimize electric battery storage.\n",
    "\n",
    "This example involves a constant and repetitive electricity price profile, combined with a perfect forecast. The agent has both the ability to memorize this profile and lives in a near Markov environment.  \n",
    "\n",
    "A real world application of using reinforcement learning to control a battery would have to deal with both a variable price profile and a non-Markov understanding of what the price profile would do in the future.  It could also involve additional reward signals, such as payments from fast frequency response needed to be balanced against price arbitrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/envs/energy_py/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/adam/git/energy_py/energy_py/experiments/analysis.py:27: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c115e58bc263>\", line 4, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 69, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import energy_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  define a total number of steps for the experiment to run\n",
    "TOTAL_STEPS = 400000\n",
    "\n",
    "#  to setup the agent we use a dictionary\n",
    "#  a dictionary allows us to eaisly save the config to csv if we want\n",
    "agent_config = {\n",
    "    'discount': 0.97,                 #  the discount rate\n",
    "    'tau': 0.001,                     #  parameter that controls the copying of weights from online to target network\n",
    "    'total_steps': TOTAL_STEPS,   \n",
    "    'batch_size': 32,                 #  size of the minibatches used for learning\n",
    "    'layers': (50, 50),               #  structure of the neural network used to approximate Q(s,a)\n",
    "    'learning_rate': 0.0001,          #  controls the stength of weight updates during learning       \n",
    "    'epsilon_decay_fraction': 0.3,    #Â  a fraction as % of total steps where epsilon decayed from 1.0 to 0.1\n",
    "    'memory_fraction': 0.4,           #  the size of the replay memory as a % of total steps\n",
    "    'memory_type': 'deque',           #  the replay memory implementation we want\n",
    "               }\n",
    "\n",
    "#  keep all of the BatteryEnv variables (episode length, efficiency etc) at their defaults\n",
    "#  we just need to let our env know where our state.csv and observation.csv are (data_path)\n",
    "env = energy_py.make_env('battery')\n",
    "\n",
    "#  set seeds for reproducibility\n",
    "env.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adam/anaconda3/envs/energy_py/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "#  initialize Tensorflow machinery\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #  Runner is a class that helps us with experiments - tracking rewards, writing environment info to csv and managing TensorBoard\n",
    "    #  in this notebook we just use it to track rewards for us\n",
    "    runner = energy_py.Runner(\n",
    "        sess,  \n",
    "        {'tb_rl': './tb_rl',\n",
    "         'ep_rewards': './rewards.csv'},\n",
    "    )\n",
    "    \n",
    "    #  add the tf session and the environment to the agent config dictionary\n",
    "    #  and initialize the agent\n",
    "    agent_config['sess'] = sess\n",
    "    agent_config['env'] = env\n",
    "    agent = energy_py.make_agent(agent_id='dqn', **agent_config)\n",
    "    \n",
    "    #  initial values for the step and episode number\n",
    "    step, episode = 0, 0\n",
    "\n",
    "    #  outer while loop runs through multiple episodes\n",
    "    while step < TOTAL_STEPS:\n",
    "        episode += 1\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        \n",
    "        #  inner while loop runs through a single episode\n",
    "        while not done:\n",
    "            step += 1\n",
    "            #  select an action\n",
    "            action = agent.act(observation)\n",
    "            \n",
    "            #  take one step through the environment\n",
    "            next_observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            #  store the experience\n",
    "            agent.remember(observation, action, reward,\n",
    "                           next_observation, done)\n",
    "            \n",
    "            #  moving to the next time step\n",
    "            observation = next_observation\n",
    "            #  saving the reward \n",
    "            runner.record_step(reward)\n",
    "            \n",
    "            #  we don't start learning until the memory is half full\n",
    "            if step > int(agent.memory.size * 0.5):\n",
    "                train_info = agent.learn()\n",
    "            \n",
    "        runner.record_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  energy_py uses TensorBoard for logging - for the scope of this notebook example we will do\n",
    "#  some simple plotting using matplotlib\n",
    "plt.plot(runner.global_rewards, label='Total reward per episode [$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we can also look at what happened in our last episode\n",
    "ep_hist = pd.DataFrame.from_dict(info)\n",
    "ep_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ep_hist.loc[:, 'new_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ep_hist.loc[:, 'electricity_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
